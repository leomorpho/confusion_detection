{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ca-5opg4Js2L"
   },
   "source": [
    "## TODO:\n",
    "Change functions names if you want to\n",
    "- `stitch_datasets(path_to_labels_jsons, path_to_open_pose_jsons)`: stitch the labels (confused, unknown, not confused, no test subject) with the OpenPose data extracted for each frame (about 100 features of body joints).\n",
    "  - Input:\n",
    "    - Path to the labels jsons\n",
    "    - Path to the OpenPose features jsons\n",
    "  - Returns:\n",
    "    - Dataframe where each row has a label and the OpenPose features\n",
    "\n",
    "- `preprocess(dataframe)`: give unit variance and zero mean to our data. \n",
    "  - Some pre-processing steps will be part of the `stitch_datasets` function\n",
    "    - Remove rows with no OpenPose feature data\n",
    "\n",
    "- `split_data(dataframes)`: Sklearn has a function for that. I'm guessing TensorFlow does as well.\n",
    "  - Input:\n",
    "    - Dataframe of the whole dataset\n",
    "  - Returns:\n",
    "    - `train_data`: a training dataset\n",
    "    - `test_data`: a testing dataset\n",
    "\n",
    "- `create_model(train_data)`: this is where the fun happens. Let's build a NN!\n",
    "\n",
    "- `test_model(test_data)`: run a cross validation test, or whatever test is appropriate and usually used for NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXONSYt24bKQ"
   },
   "source": [
    "## NN architecture\n",
    "[The mostly complete chart of Neural Networks, explained](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464)\n",
    "\n",
    "We want:\n",
    "- Some temporality\n",
    "\n",
    "Arcitectures to start from:\n",
    "- RNN: Recurrent Neural Network\n",
    "  - Simple model with context preservation\n",
    "- LSTM: Long / Short Term Memory\n",
    "  - More complicated than RNN, but better for sequences (I think?)\n",
    "- GRU: Gated Recurrent Unit\n",
    "  - Similar to LSTM but less ressource intensive and similar performance\n",
    "- AE / VAE: Auto-Encoder / Variational Auto-Encoder\n",
    "  - Good at classfying patterns. Seems to be more for unsuperverised learning, which is not what we're after. I wonder if it can do logistic classification. Perhaps wer could generate stick figures of confused people. A little off topic though.\n",
    "- SVM: Support Vector Machine\n",
    "  - Can be used as a baseline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvYhGcFL1Xws"
   },
   "source": [
    "## Download our dataset from our Dropbox and our main dependencies\n",
    "Make sure to add all newly created data to the `combined_jsons` folder in our shared dropbox. The data will be directly curled from it.\n",
    "\n",
    "Uncomment the below cell when running in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPynH3BYQ8A9"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import os\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "# \n",
    "# DATA_DIR = \"data\"\n",
    "# REDOWNLOAD = True\n",
    "# \n",
    "# if REDOWNLOAD:\n",
    "#   shutil.rmtree(DATA_DIR)\n",
    "# \n",
    "# if not os.path.exists(DATA_DIR):\n",
    "#   !curl -L -o data.zip https://www.dropbox.com/sh/3ty3gszbpexan9q/AAC4F7GnYk-o0CU-HvM29sd9a?dl=0\n",
    "#   !unzip data.zip -d data\n",
    "#   !rm data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Vh1vJwa4qGm"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtK_Uvwi3bns"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import *\n",
    "import json\n",
    "\n",
    "DATA_DIR = \"data/combined_jsons\"\n",
    "dataset_paths = glob(f\"{DATA_DIR}/*\")\n",
    "\n",
    "# Create single list object from all the JSONs\n",
    "raw_sequences: List[List[List[float]]] = []\n",
    "for path in dataset_paths:\n",
    "  with open(path, \"r\") as f:\n",
    "    raw_sequences.append(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZddK8WY5ILW"
   },
   "source": [
    "Get centroid for every frame. If the centroid differs widely between 2 frames, it may indicate that different people were picked up by OpenPose.\n",
    "Centroid code taken from [here](https://stackoverflow.com/questions/23020659/fastest-way-to-calculate-the-centroid-of-a-set-of-coordinate-tuples-in-python-wi).\n",
    "\n",
    "Format of OpenPose output can be found [here](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/output.md). A frame is represented by `x1,y1,c1,x2,y2,c2,...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7Z-9obS8xgv"
   },
   "source": [
    "If a dropped frame is between 2 valid sequences, consider stitching them back together.\n",
    "* Drop frames which have **no subject** in them. DONE.\n",
    "* Drop frames which have **wrong** subject in them.  DONE.\n",
    "* Give unit variance (and zero mean?) to all points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWXnNNXN5Jwc"
   },
   "outputs": [],
   "source": [
    "from jupyter_tools.preprocessing import stitch_frames\n",
    "\n",
    "parsed_sequences = stitch_frames(raw_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Use an autoencoder to reduce the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Create 3 models\n",
    "* Simple RNN\n",
    "* LSTM/GRU RNN\n",
    "\n",
    "For testing, it would be beneficial to write a function (in `jupyter_tools`) to display the frames as a video with a label indicating the prediction from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7abbf1c8e6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsYRAU0LEPnY"
   },
   "source": [
    "## Resources\n",
    "### Educational\n",
    "* [DeepMind deep learning lectures](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF)\n",
    "### Annotation tools\n",
    "* [List of open source solutions](https://www.simonwenkel.com/2019/07/19/list-of-annotation-tools-for-machine-learning-research.html)\n",
    "* [opencv/cvat](https://github.com/opencv/cvat)\n",
    "* [alexandre01/UltimateLabeling](https://github.com/alexandre01/UltimateLabeling)\n",
    "### Existing trained models\n",
    "* [onnx/models](https://github.com/onnx/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8kpbdaCEslu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "confusion_detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
